<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CS180 Project 4 - Neural Radiance Field: Implementation of camera calibration, neural fields, and NeRF from multi-view images">
  <meta name="keywords" content="CS180, Computer Vision, NeRF, Neural Radiance Fields, Camera Calibration, Neural Networks, 3D Reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CS180 Project 4: Neural Radiance Field</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
  <!-- MathJax for LaTeX equations -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://cal-cs180.github.io/fa25/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      <span>CS180 Home</span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Projects
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="./index.html">
            Project 0
          </a>
          <a class="navbar-item" href="./project1.html">
            Project 1
          </a>
          <a class="navbar-item" href="./project2.html">
            Project 2
          </a>
          <a class="navbar-item" href="./project3.html">
            Project 3
          </a>
          <a class="navbar-item" href="./project4.html">
            Project 4
          </a>
        </div>
      </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CS180 Project 4: Neural Radiance Field</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">CS180: Intro to Computer Vision and Computational Photography</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Fall 2025</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">

          <!-- Part 0: Camera Calibration and 3D Scanning -->
          <h2 class="title is-2">Part 0: Camera Calibration and 3D Scanning</h2>
          
          <p class="is-size-5">
            In this section, I calibrated the camera using ArUco markers and captured a 3D scan of an object 
            for later NeRF reconstruction. 
          </p>

          <!-- Part 0.1: Calibrating Your Camera -->
          <h3 class="title is-3">Part 0.1: Calibrating Your Camera</h3>
          
          <div class="box">
            <h4 class="title is-4">Camera Calibration Process</h4>
            <p class="is-size-5">
              Camera calibration involves capturing multiple images of a known pattern (ArUco markers) from 
              different angles and distances. By detecting the marker corners across all images and knowing 
              their 3D positions, I can solve for the camera's intrinsic matrix \(\mathbf{K}\) and distortion 
              coefficients using <code>cv2.calibrateCamera()</code>.
            </p>
            

          <!-- Part 0.2: Capturing a 3D Object Scan -->
          <h3 class="title is-3">Part 0.2: Capturing a 3D Object Scan</h3>
          
          <div class="box">
            <h4 class="title is-4">Object Scan Dataset</h4>
            <p class="is-size-5">
              I captured 80 images of my chosen object (bird doll) from varying angles, ensuring the ArUco tag 
              remains visible in each frame. 
            </p>

          <!-- Part 0.3: Estimating Camera Pose -->
          <h3 class="title is-3">Part 0.3: Estimating Camera Pose</h3>
          
          <div class="box">
            <h4 class="title is-4">Pose Estimation using PnP</h4>
            <p class="is-size-5">
              For each captured image, I detect the ArUco tag and use <code>cv2.solvePnP()</code> 
              to estimate the camera pose (rotation and translation) relative to the tag. 
            </p>
            
            <div class="box">
              <h5 class="title is-5">Camera Frustums Visualization (View 1)</h5>
              <img src="./static/images/project_4/part_0/viser_1.png" alt="Camera frustums visualization view 1" style="width: 100%;">
            </div>

            <div class="box">
              <h5 class="title is-5">Camera Frustums Visualization (View 2)</h5>
              <img src="./static/images/project_4/part_0/viser_2.png" alt="Camera frustums visualization view 2" style="width: 100%;">
            </div>
          </div>

          <!-- Part 1: Fit a Neural Field to a 2D Image -->
          <h2 class="title is-2">Part 1: Fit a Neural Field to a 2D Image</h2>
          
          <p class="is-size-5">
            In this section, I fit a neural network to represent a single 2D image. 
          </p>

          <div class="box">
            <h4 class="title is-4">Model Architecture</h4>
            <p class="is-size-5">
              The neural field is implemented as a Multi-Layer Perceptron (MLP) with the following specifications.
            </p>
            <ul class="is-size-5">
              <li><strong>Input:</strong> Positional encoded 2D coordinates \((x, y)\) normalized to [0, 1]</li>
              <li><strong>Positional Encoding:</strong> Sinusoidal encoding with frequency parameter \(L\) (tested with \(L = 5, 12, 15\))</li>
              <li><strong>Architecture:</strong> 4-layer MLP with ReLU activations</li>
              <li><strong>Hidden Dimensions:</strong> Tested with widths of 128, 256, and 512 units</li>
              <li><strong>Activation Functions:</strong> ReLU for hidden layers, Sigmoid for output</li>
              <li><strong>Output:</strong> RGB color values in [0, 1]</li>
              <li><strong>Loss Function:</strong> Mean Squared Error (MSE)</li>
              <li><strong>Optimizer:</strong> Adam optimizer</li>
              <li><strong>Learning Rate:</strong> 1e-2 (0.01)</li>
              <li><strong>Training:</strong> 3000 epochs with batch size of 10,000 pixels per epoch</li>
            </ul>
          </div>


          <div class="box">
            <h4 class="title is-4">Training Progression - Fox Image</h4>
            <p class="is-size-5">
              Training progression showing how the neural field learns to represent the image over 3000 epochs (Width=256, L=12):
            </p>
            <div class="columns is-multiline">
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 1</h6>
                  <img src="./static/images/project_4/part_1/part1_results_fox_256_12/reconstructed_epoch_0001.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 400</h6>
                  <img src="./static/images/project_4/part_1/part1_results_fox_256_12/reconstructed_epoch_0400.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 800</h6>
                  <img src="./static/images/project_4/part_1/part1_results_fox_256_12/reconstructed_epoch_0800.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 1200</h6>
                  <img src="./static/images/project_4/part_1/part1_results_fox_256_12/reconstructed_epoch_1200.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 2000</h6>
                  <img src="./static/images/project_4/part_1/part1_results_fox_256_12/reconstructed_epoch_2000.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 3000 (Final)</h6>
                  <img src="./static/images/project_4/part_1/part1_results_fox_256_12/reconstructed_epoch_3000.png" style="width: 100%;">
                </div>
              </div>
            </div>
          </div>

          <div class="box">
            <h4 class="title is-4">Final Reconstruction Comparison - Fox Image</h4>
            <img src="./static/images/project_4/part_1/part1_results_fox_256_12/comparison.png" alt="Original vs reconstructed" style="width: 100%;">
          </div>

          <div class="box">
            <h4 class="title is-4">Training Progression - My Custom Image (Bird Doll)</h4>
            <p class="is-size-5">
              Training progression on my custom image over 3000 epochs (Width=512, L=15):
            </p>
            <div class="columns is-multiline">
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 1</h6>
                  <img src="./static/images/project_4/part_1/part1_results_512_15_mine/reconstructed_epoch_0001.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 400</h6>
                  <img src="./static/images/project_4/part_1/part1_results_512_15_mine/reconstructed_epoch_0400.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 800</h6>
                  <img src="./static/images/project_4/part_1/part1_results_512_15_mine/reconstructed_epoch_0800.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 1200</h6>
                  <img src="./static/images/project_4/part_1/part1_results_512_15_mine/reconstructed_epoch_1200.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 2000</h6>
                  <img src="./static/images/project_4/part_1/part1_results_512_15_mine/reconstructed_epoch_2000.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 3000 (Final)</h6>
                  <img src="./static/images/project_4/part_1/part1_results_512_15_mine/reconstructed_epoch_3000.png" style="width: 100%;">
                </div>
              </div>
            </div>
          </div>

          <div class="box">
            <h4 class="title is-4">Final Reconstruction Comparison - Bird Doll</h4>
            <img src="./static/images/project_4/part_1/part1_results_512_15_mine/comparison.png" alt="Original vs reconstructed bird doll" style="width: 100%;">
          </div>

          <div class="box">
            <h4 class="title is-4">Training Curves</h4>
            <img src="./static/images/project_4/part_1/part1_results_512_15_mine/training_curves.png" alt="Training curves for bird doll" style="width: 100%;">
          </div>

          <div class="box">
            <h4 class="title is-4">Hyperparameter Analysis</h4>
            <p class="is-size-5">
              Below I compare the effects of different positional encoding frequencies and network widths 
              on reconstruction quality.
            </p>
            
            <div class="box">
              <h5 class="title is-5">Effect of Positional Encoding Frequency</h5>
              <p class="is-size-6">
                Comparing different encoding frequencies with the same network width (256):
              </p>
              <div class="columns">
                <div class="column is-half">
                  <div class="box">
                    <h6 class="title is-6">Low Frequency (L=5)</h6>
                    <img src="./static/images/project_4/part_1/part1_results_fox_256_5/final_reconstruction.png" style="width: 100%;">
                  </div>
                </div>
                <div class="column is-half">
                  <div class="box">
                    <h6 class="title is-6">High Frequency (L=12)</h6>
                    <img src="./static/images/project_4/part_1/part1_results_fox_256_12/final_reconstruction.png" style="width: 100%;">
                  </div>
                </div>
              </div>
              <div class="box has-background-info-light">
                <p class="is-size-6">
                  <strong>Observation:</strong> Higher encoding frequencies (larger \(L\)) allow the network to represent 
                  higher-frequency details in the image.
                </p>
              </div>
            </div>

            <div class="box">
              <h5 class="title is-5">Effect of Network Width</h5>
              <p class="is-size-6">
                Comparing different network widths with the same encoding frequency (L=12):
              </p>
              <div class="columns">
                <div class="column is-half">
                  <div class="box">
                    <h6 class="title is-6">Narrow Network (Width=128)</h6>
                    <img src="./static/images/project_4/part_1/part1_results_fox_128_12/final_reconstruction.png" style="width: 100%;">
                  </div>
                </div>
                <div class="column is-half">
                  <div class="box">
                    <h6 class="title is-6">Wide Network (Width=256)</h6>
                    <img src="./static/images/project_4/part_1/part1_results_fox_256_12/final_reconstruction.png" style="width: 100%;">
                  </div>
                </div>
              </div>
              <div class="box has-background-info-light">
                <p class="is-size-6">
                  <strong>Observation:</strong> Wider networks (more hidden units) generally provide better reconstruction 
                  quality due to increased capacity. However, this comes at the cost of more parameters and longer training time. 

                </p>
              </div>
            </div>
          </div>

          <div class="box">
            <h4 class="title is-4">Training Curves and PSNR</h4>
            <p class="is-size-5">
              Peak Signal-to-Noise Ratio (PSNR) measures reconstruction quality. Higher PSNR indicates 
              better image quality. The plot shows both training loss (MSE) and PSNR over epochs:
            </p>
            <img src="./static/images/project_4/part_1/part1_results_fox_256_12/training_curves.png" alt="Training curves" style="width: 100%;">
          </div>

          <!-- Part 2: Fit a Neural Radiance Field from Multi-view Images -->
          <h2 class="title is-2">Part 2: Fit a Neural Radiance Field from Multi-view Images</h2>
          
          <p class="is-size-5">
            In this section, I implemented a Neural Radiance Field (NeRF) that allows me to synthesize novel views of a 3D scene from multiple training images.
          </p>

          <div class="box">
            <h4 class="title is-4">Implementation Details</h4>
            
            <h5 class="title is-5">1. Ray Generation</h5>
            <p class="is-size-5">
              For each pixel coordinate \((u, v)\), I generate a camera ray using the <code>pixel_to_ray</code> function:
            </p>
            <ol class="is-size-5">
              <li>Convert pixel coordinates to homogeneous coordinates: \([u, v, 1]^T\)</li>
              <li>Apply inverse camera intrinsics \(\mathbf{K}^{-1}\) to get camera-space direction</li>
              <li>Transform to world space using camera-to-world matrix \(\mathbf{c2w}\)</li>
              <li>Normalize the direction vector to unit length</li>
            </ol>
            <p class="is-size-5">
              Each ray is parameterized as \(\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}\) where \(\mathbf{o}\) is the camera center 
              (extracted from \(\mathbf{c2w}\)) and \(\mathbf{d}\) is the normalized ray direction.
            </p>

            <h5 class="title is-5" style="margin-top: 20px;">2. Sampling Along Rays</h5>
            <p class="is-size-5">
              I sample 64 points along each ray between near (\(t_n\)) and far (\(t_f\)) bounds using stratified sampling:
            </p>
            <ul class="is-size-5">
              <li>Divide the ray into 64 equal bins</li>
              <li>Uniformly sample one point within each bin to ensure coverage</li>
              <li>During training, add random perturbations within bins for better optimization</li>
              <li>Compute 3D sample positions: \(\mathbf{x}_i = \mathbf{o} + t_i\mathbf{d}\)</li>
            </ul>

            <h5 class="title is-5" style="margin-top: 20px;">3. Volume Rendering</h5>
            <p class="is-size-5">
              After querying the NeRF network for RGB and density at each sample point, I composite them using the volume rendering equation:
            </p>
            <div class="content has-text-centered" style="margin: 16px 0;">
              $$C(\mathbf{r}) = \sum_{i=1}^{N} T_i \cdot \alpha_i \cdot \mathbf{c}_i$$
            </div>
            <p class="is-size-5">
              where:
            </p>
            <ul class="is-size-5">
              <li>\(\alpha_i = 1 - \exp(-\sigma_i \delta_i)\) is the opacity of sample \(i\)</li>
              <li>\(\delta_i = t_{i+1} - t_i\) is the distance between adjacent samples</li>
              <li>\(T_i = \exp\left(-\sum_{j=1}^{i-1} \sigma_j \delta_j\right)\) is the accumulated transmittance</li>
              <li>\(\mathbf{c}_i\) is the RGB color at sample \(i\)</li>
            </ul>

            <h5 class="title is-5" style="margin-top: 20px;">4. Training Strategy</h5>
            <p class="is-size-5">
              The model is optimized using random ray sampling:
            </p>
            <ul class="is-size-5">
              <li>Pre-compute all rays for all training images at initialization</li>
              <li>Each training iteration samples 10,000 random rays from the full dataset</li>
              <li>Render these rays through the NeRF to get predicted colors</li>
              <li>Compute MSE loss between predicted and ground truth colors</li>
              <li>Update network weights using Adam optimizer with learning rate 5e-4</li>
            </ul>
          </div>

          <div class="box">
            <h4 class="title is-4">Ray and Sample Visualization</h4>
            <p class="is-size-5">
              Visualization of sampled rays and points in 3D space. 
              This shows up to 100 randomly selected rays cast from the camera through the image plane, 
              along with sample points along each ray used for volume rendering
            </p>
            <div class="columns">
              <div class="column is-half">
                <div class="box">
                  <h6 class="title is-6">View 1</h6>
                  <img src="./static/images/project_4/part2/ray_1.jpg" alt="Ray visualization 1" style="width: 100%;">
                </div>
              </div>
              <div class="column is-half">
                <div class="box">
                  <h6 class="title is-6">View 2</h6>
                  <img src="./static/images/project_4/part2/ray_2.jpg" alt="Ray visualization 2" style="width: 100%;">
                </div>
              </div>
            </div>
          </div>

          <div class="box">
            <h4 class="title is-4">Training Progression Visualization</h4>
            
            <div class="columns is-multiline">
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 200</h6>
                  <img src="./static/images/project_4/part2/lego/val_epoch_00200.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 800</h6>
                  <img src="./static/images/project_4/part2/lego/val_epoch_00800.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 1600</h6>
                  <img src="./static/images/project_4/part2/lego/val_epoch_01600.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 2600</h6>
                  <img src="./static/images/project_4/part2/lego/val_epoch_02600.png" style="width: 100%;">
                </div>
              </div>
              <div class="column is-one-third">
                <div class="box">
                  <h6 class="title is-6">Epoch 3000 (Final)</h6>
                  <img src="./static/images/project_4/part2/lego/val_epoch_03000.png" style="width: 100%;">
                </div>
              </div>
            </div>
          </div>

          <div class="box">
            <h4 class="title is-4">Training Configuration</h4>
            <p class="is-size-5">
              The NeRF model was trained with the following hyperparameters:
            </p>
            <ul class="is-size-5">
              <li><strong>Positional Encoding:</strong> L=10 for 3D positions, L=4 for view directions</li>
              <li><strong>Network Architecture:</strong> 256 hidden units, 8 layers for position processing, 3 layers for view-dependent color</li>
              <li><strong>Samples Per Ray:</strong> 64 points sampled along each ray</li>
              <li><strong>Near/Far Bounds:</strong> 2.0 / 6.0 for the Lego dataset</li>
              <li><strong>Batch Size:</strong> 10,000 rays per gradient step</li>
              <li><strong>Learning Rate:</strong> 5e-4 with Adam optimizer</li>
              <li><strong>Training Epochs:</strong> 3,000 epochs</li>
            </ul>
          </div>

          <div class="box">
            <h4 class="title is-4">Validation PSNR Curve</h4>
            <p class="is-size-5">
              The validation PSNR reaches above 23 dB, demonstrating successful learning of the 3D scene:
            </p>
            <img src="./static/images/project_4/part2/lego/curve.jpg" alt="PSNR curve" style="width: 100%;">
            
        </div>

          <div class="box">
            <h4 class="title is-4">Novel View Synthesis </h4>
            
            <div class="columns">
              <div class="column">
                <div class="box">
                  <h6 class="title is-6">360Â° Rotation View</h6>
                  <img src="./static/images/project_4/part2/lego/rotation.gif" alt="Lego rotation" style="width: 100%;">
                </div>
              </div>
            </div>


          <!-- Part 2.6: Training with Your Own Data -->
          <h3 class="title is-3">Part 2.6: Training NeRF on Custom Object</h3>
          
          <div class="box">
            <h4 class="title is-4">Custom Object: Bird Doll NeRF</h4>
            
            <div class="box">
              <h5 class="title is-5">Implementation Changes and Hyperparameters</h5>
              <p class="is-size-5">
                Key modifications made for real-world data compared to the synthetic Lego dataset:
              </p>
              <ul class="is-size-5">
                <li><strong>Near/Far Bounds:</strong> 0.02 / 0.5
                     (adjusted from 2.0/6.0 for Lego dataset due to closer capture distance, firstly I tried 2.0/6.0 but found output are all black, then I added caculation during dataset creation to get the correct near and far bounds)</li>
                <li><strong>Learning Rate:</strong> 5e-4 (Adam optimizer)</li>
                <li><strong>Training Epochs:</strong> 12,000 epochs for better quality</li>
                <li><strong>Image Resolution:</strong> Downsampled 5 times to reduce GPU memory usage</li>
                <li><strong>Batch Size:</strong> 10,000 rays per training step</li>
                <li><strong>Positional Encoding:</strong> L=10 for positions, L=4 for directions</li>
                <li><strong>Network Architecture:</strong> Increased hidden units to 512 since that the image resolution is higher, 8 layers for position, 3 layers for view-dependent color</li>
              </ul>
            </div>

            <div class="box">
              <h5 class="title is-5">Validation PSNR Curve</h5>
              <img src="./static/images/project_4/part_2.6/bird/curve.jpg" alt="Bird training curve" style="width: 100%;">
            </div>

            <div class="box">
              <h5 class="title is-5">Training Progression Visualization</h5>
              <div class="columns is-multiline">
                <div class="column is-one-third">
                  <div class="box">
                    <h6 class="title is-6">Epoch 500</h6>
                    <img src="./static/images/project_4/part_2.6/bird/val_epoch_00500.png" style="width: 100%;">
                  </div>
                </div>
                <div class="column is-one-third">
                  <div class="box">
                    <h6 class="title is-6">Epoch 2000</h6>
                    <img src="./static/images/project_4/part_2.6/bird/val_epoch_02000.png" style="width: 100%;">
                  </div>
                </div>
                <div class="column is-one-third">
                  <div class="box">
                    <h6 class="title is-6">Epoch 4000</h6>
                    <img src="./static/images/project_4/part_2.6/bird/val_epoch_04000.png" style="width: 100%;">
                  </div>
                </div>
                <div class="column is-one-third">
                  <div class="box">
                    <h6 class="title is-6">Epoch 7000</h6>
                    <img src="./static/images/project_4/part_2.6/bird/val_epoch_07000.png" style="width: 100%;">
                  </div>
                </div>
                <div class="column is-one-third">
                  <div class="box">
                    <h6 class="title is-6">Epoch 10000 (Final)</h6>
                    <img src="./static/images/project_4/part_2.6/bird/val_epoch_10000.png" style="width: 100%;">
                  </div>
                </div>
              </div>
            </div>

            <div class="box">
              <h5 class="title is-5">Novel View Synthesis</h5>

              <div class="columns">
                <div class="column">
                  <div class="box">
                    <img src="./static/images/project_4/part_2.6/bird/rotation.gif" alt="Bird rotation" style="width: 100%;">
                  </div>
                </div>
              </div>
            </div>    

        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        This website was adapted from <a href="https://github.com/nerfies/nerfies.github.io">nerfies's website</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>

